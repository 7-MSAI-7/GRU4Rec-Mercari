# -*- coding: utf-8 -*-
"""
ì´ íŒŒì¼ì€ í•™ìŠµëœ ì¶”ì²œ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ìƒˆë¡œìš´ ì¶”ì²œì„ ìƒì„±í•˜ëŠ” 'ì¶”ë¡ (inference)' ê³¼ì •ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
í•™ìŠµëœ ëª¨ë¸ê³¼ ê´€ë ¨ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¨ ë’¤, íŠ¹ì • ì‚¬ìš©ì í–‰ë™ ì‹œí€€ìŠ¤ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ì•„
ë‹¤ìŒì— ì˜¬ ë§Œí•œ ì•„ì´í…œì„ ì˜ˆì¸¡í•˜ì—¬ ì¶”ì²œ ëª©ë¡ì„ ìƒì„±í•©ë‹ˆë‹¤.
"""
import os
import pickle
import random
import glob
import torch
import pandas as pd
from sentence_transformers import SentenceTransformer

# --- Local Imports ---
# ë‹¤ë¥¸ íŒŒì¼ì— ì •ì˜ëœ í•¨ìˆ˜ë‚˜ ì„¤ì •ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
import src.settings as config  # ì„¤ì •ê°’ì„ ë‹´ê³  ìˆëŠ” íŒŒì¼
from src.models.gru_model import GruModel  # í•™ìŠµëœ ëª¨ë¸ê³¼ ë™ì¼í•œ êµ¬ì¡°ì˜ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ê¸° ìœ„í•¨
from src.training_engine import generate_recommendations  # ì¶”ì²œì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜


# SentenceTransformer ëª¨ë¸ì€ í…ìŠ¤íŠ¸(ì˜ˆ: ìƒí’ˆëª…)ë¥¼ ì»´í“¨í„°ê°€ ì´í•´í•  ìˆ˜ ìˆëŠ” ìˆ«ì ë²¡í„°(ì„ë² ë”©)ë¡œ ë³€í™˜í•˜ëŠ” ëª¨ë¸ì…ë‹ˆë‹¤.
# í”„ë¡œê·¸ë¨ ì‹œì‘ ì‹œ í•œ ë²ˆë§Œ ë¡œë“œí•˜ì—¬ ê³„ì† ì‚¬ìš©í•©ë‹ˆë‹¤.
sentence_model = SentenceTransformer(
    "sentence-transformers/all-MiniLM-L6-v2"
)


def load_inference_dependencies():
    """
    ì¶”ë¡ (ì˜ˆì¸¡)ì— í•„ìš”í•œ ëª¨ë¸ê³¼ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.
    í•™ìŠµ ê³¼ì •ì—ì„œ ì €ì¥ëœ ëª¨ë¸ ê°€ì¤‘ì¹˜ì™€ ì•„ì´í…œ ì •ë³´ë¥¼ ë¶ˆëŸ¬ì™€ ì¶”ë¡  ì¤€ë¹„ë¥¼ í•©ë‹ˆë‹¤.
    """
    print("ì¶”ë¡ ì— í•„ìš”í•œ íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤...")

    # ì•„ì´í…œ IDì™€ ë‚´ë¶€ ì¸ë±ìŠ¤ë¥¼ ë§¤í•‘í•˜ëŠ” ì‚¬ì „ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
    # ì´ë¥¼ í†µí•´ ëª¨ë¸ì´ ì´í•´í•˜ëŠ” ì¸ë±ìŠ¤ë¥¼ ì‹¤ì œ ì•„ì´í…œ IDë¡œ ë³€í™˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    if os.path.exists(config.ITEM_ID_IDX_PATH):
        with open(config.ITEM_ID_IDX_PATH, "rb") as f:
            item_id_to_idx = pickle.load(f)
        idx_to_item_id = {v: k for k, v in item_id_to_idx.items()}
    else:
        # íŒŒì¼ì´ ì—†ìœ¼ë©´ ì˜¤ë¥˜ë¥¼ ë°œìƒì‹œì¼œ í”„ë¡œê·¸ë¨ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.
        raise FileNotFoundError(f"{config.ITEM_ID_IDX_PATH} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    print(f"í•™ìŠµ ëª¨ë¸ ë¡œë“œ ì¤‘...")
    if os.path.exists(config.MODEL_SAVE_PATH):
        model_state_dict = torch.load(config.MODEL_SAVE_PATH, map_location=config.DEVICE)
    else:
        raise FileNotFoundError(f"{config.MODEL_SAVE_PATH} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # ì´ë²¤íŠ¸(ì‚¬ìš©ì í–‰ë™)ì™€ ë‚´ë¶€ ì¸ë±ìŠ¤ë¥¼ ë§¤í•‘í•˜ëŠ” ì‚¬ì „ì„ ì •ì˜í•©ë‹ˆë‹¤.
    # í•™ìŠµ ë•Œ ì‚¬ìš©í–ˆë˜ ê²ƒê³¼ ë™ì¼í•œ êµ¬ì¡°ì—¬ì•¼ í•©ë‹ˆë‹¤.
    event_to_idx = {
        "<PAD_EVENT>": 0,  # ì‹œí€€ìŠ¤ ê¸¸ì´ë¥¼ ë§ì¶”ê¸° ìœ„í•œ ê°€ì§œ ì´ë²¤íŠ¸
        "item_view": 1,  # ì•„ì´í…œ ì¡°íšŒ
        "item_like": 2,  # 'ì¢‹ì•„ìš”'
        "item_add_to_cart_tap": 3,  # ì¥ë°”êµ¬ë‹ˆì— ë‹´ê¸°
        "offer_make": 4,  # ê°€ê²© ì œì•ˆ
        "buy_start": 5,  # êµ¬ë§¤ ì‹œì‘
        "buy_comp": 6,  # êµ¬ë§¤ ì™„ë£Œ
    }

    # ëª¨ë¸ì„ ì´ˆê¸°í™”í•˜ê³  í•™ìŠµëœ ê°€ì¤‘ì¹˜ë¥¼ ë¡œë“œí•  ì¤€ë¹„ë¥¼ í•©ë‹ˆë‹¤.
    # í•™ìŠµ ë•Œì™€ ë™ì¼í•œ íŒŒë¼ë¯¸í„°ë¡œ ëª¨ë¸ êµ¬ì¡°ë¥¼ ë§Œë“¤ì–´ì•¼ í•©ë‹ˆë‹¤.
    print(f"ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")
    model_args = {
        "device": config.DEVICE,
        "name_embedding_dim": config.NAME_EMBEDDING_DIM,
        "event_embedding_dim": config.EVENT_EMBEDDING_DIM,
        "gru_hidden_dim": config.GRU_HIDDEN_DIM,
        "gru_num_layers": config.GRU_NUM_LAYERS,
        "dropout_rate": config.DROPOUT_RATE,
        "n_events": len(event_to_idx),  # ì „ì²´ ì´ë²¤íŠ¸ ì¢…ë¥˜ ìˆ˜
        "n_items": len(item_id_to_idx),  # ì „ì²´ ì•„ì´í…œ ì¢…ë¥˜ ìˆ˜
    }
    model = GruModel(**model_args)
    model.load_state_dict(model_state_dict)

    # ëª¨ë¸ì„ ì¶”ë¡  ëª¨ë“œ(eval)ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.
    # ì´ëŠ” í•™ìŠµ ë•Œì™€ ë‹¬ë¦¬ ë“œë¡­ì•„ì›ƒ ë“±ì˜ ê¸°ëŠ¥ì„ ë¹„í™œì„±í™”í•˜ì—¬ ì¼ê´€ëœ ì˜ˆì¸¡ì„ í•˜ë„ë¡ í•©ë‹ˆë‹¤.
    model.to(config.DEVICE)
    model.eval()

    print("ë¡œë“œ ì™„ë£Œ.")
    # ì¤€ë¹„ëœ ëª¨ë¸ê³¼ ë°ì´í„°(ì‚¬ì „)ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    return model, idx_to_item_id, item_id_to_idx


if __name__ == "__main__":
    # ì´ ìŠ¤í¬ë¦½íŠ¸ê°€ ì§ì ‘ ì‹¤í–‰ë  ë•Œ ì•„ë˜ ì½”ë“œê°€ ì‹¤í–‰ë©ë‹ˆë‹¤.
    
    # ì¶”ë¡ ì— í•„ìš”í•œ ëª¨ë¸ê³¼ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
    model, idx_to_item_id, item_id_to_idx = load_inference_dependencies()

    # ì¶”ì²œì˜ ê¸°ë°˜ì´ ë  ì•„ì´í…œ ì •ë³´ ë°ì´í„°í”„ë ˆì„ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
    # df_item_info = pd.read_parquet(
    #     r"D:/Downloads/merrec/20230501/000000000000.parquet"
    # )
    parquet_files = glob.glob(config.DATA_PATH)
    df_item_info = pd.concat([pd.read_parquet(file) for file in parquet_files])

    # ì•„ì´í…œ IDë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì¤‘ë³µì„ ì œê±°í•˜ê³  í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒí•©ë‹ˆë‹¤.
    df_item_info = (
        df_item_info[["item_id", "name", "c0_name", "c1_name", "c2_name"]]
        .drop_duplicates(subset=["item_id"])
        .set_index("item_id")
    )

    # ì´ë²¤íŠ¸ ë§µí•‘ ì‚¬ì „ì„ ë‹¤ì‹œ ì •ì˜í•©ë‹ˆë‹¤. (load_inference_dependencies í•¨ìˆ˜ ë‚´ì˜ ê²ƒê³¼ ë™ì¼)
    event_to_idx = {
        "<PAD_EVENT>": 0,
        "item_view": 1,
        "item_like": 2,
        "item_add_to_cart_tap": 3,
        "offer_make": 4,
        "buy_start": 5,
        "buy_comp": 6,
    }

    # --- ì¶”ì²œ ìƒì„±ì„ ìœ„í•œ ê°€ìƒ ì‹œë‚˜ë¦¬ì˜¤ ---
    print("ì¶”ì²œ ê²°ê³¼ ìƒì„± ì˜ˆì‹œ... ğŸ›ï¸")
        
    # ì•„ì´í…œ ì •ë³´ì—ì„œ ë¬´ì‘ìœ„ë¡œ 1~10ê°œì˜ ì•„ì´í…œ-ì´ë²¤íŠ¸ ì‹œí€€ìŠ¤ë¥¼ ìƒ˜í”Œë§í•˜ì—¬ ê°€ìƒ ì‚¬ìš©ì í–‰ë™ì„ ë§Œë“­ë‹ˆë‹¤.
    item_event_sequences = df_item_info.sample(n=random.randint(1, 10))
    item_event_sequences = item_event_sequences.apply(
        lambda x: (
            x["name"],  # ìƒí’ˆëª…
            random.choice(list(event_to_idx.keys())[1:]),  # ëœë¤ í–‰ë™
            x["c0_name"],  # ëŒ€ë¶„ë¥˜ ì¹´í…Œê³ ë¦¬
            x["c1_name"],  # ì¤‘ë¶„ë¥˜ ì¹´í…Œê³ ë¦¬
            x["c2_name"],  # ì†Œë¶„ë¥˜ ì¹´í…Œê³ ë¦¬
        ),
        axis=1,
    ).tolist()
    
    # ëª¨ë¸ì— ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•  ì‹œí€€ìŠ¤ ì •ë³´ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
    print(f"ì¶”ì²œ ìƒì„±ì„ ìœ„í•œ ì…ë ¥ ì‹œí€€ìŠ¤:")
    for item_event_sequence in item_event_sequences:
        print(
            f"  - ìƒí’ˆëª…: {item_event_sequence[0]:>80} | í–‰ë™: {item_event_sequence[1]:>20}"
            f"  - ì¹´í…Œê³ ë¦¬: {(item_event_sequence[2] if item_event_sequence[2] else ' '):<20} | {(item_event_sequence[3] if item_event_sequence[3] else ' '):<20} | {(item_event_sequence[4] if item_event_sequence[4] else ' '):<20}"
        )

    # ì¤€ë¹„ëœ ëª¨ë¸ê³¼ ì…ë ¥ ì‹œí€€ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¶”ì²œì„ ìƒì„±í•©ë‹ˆë‹¤.
    recommendations_df = generate_recommendations(
        model=model,
        item_event_sequences=item_event_sequences,  # ì…ë ¥ ì‹œí€€ìŠ¤
        top_n=config.TOP_N,  # ìƒìœ„ ëª‡ ê°œë¥¼ ì¶”ì²œí• ì§€
        device=config.DEVICE,
        idx_to_item_id=idx_to_item_id,
        df_item_info=df_item_info,
        event_to_idx=event_to_idx
    )

    # ìƒì„±ëœ ì¶”ì²œ ê²°ê³¼ë¥¼ í™•ì¸í•˜ê³  ì¶œë ¥í•©ë‹ˆë‹¤.
    if not recommendations_df.empty:
        print(
            f"\nğŸ ë‹¤ìŒìœ¼ë¡œ ì´ ì•„ì´í…œë“¤ì€ ì–´ë– ì„¸ìš”? (ìƒìœ„ {config.TOP_N}ê°œ ì¶”ì²œ ê²°ê³¼)"
        )
        print(recommendations_df.to_string())
    else:
        print("ì£„ì†¡í•´ìš”, ì§€ê¸ˆì€ ì¶”ì²œí•´ë“œë¦´ ë§Œí•œ ì•„ì´í…œì„ ì°¾ì§€ ëª»í–ˆì–´ìš”. ğŸ˜”")

