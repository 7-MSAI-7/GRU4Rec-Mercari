# -*- coding: utf-8 -*-
"""
ì´ íŒŒì¼ì€ ì¶”ì²œ ì‹œìŠ¤í…œ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ëŠ” ì „ì²´ ê³¼ì •ì„ ë‹´ê³  ìžˆìŠµë‹ˆë‹¤.
ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ê³ , ì „ì²˜ë¦¬í•˜ë©°, ëª¨ë¸ì„ ì •ì˜í•˜ê³ , í•™ìŠµì‹œí‚¨ í›„, ì„±ëŠ¥ì„ í‰ê°€í•˜ê³ , ìµœì¢…ì ìœ¼ë¡œ ëª¨ë¸ì„ ì €ìž¥í•©ë‹ˆë‹¤.
ë§ˆì§€ë§‰ìœ¼ë¡œ, í•™ìŠµëœ ëª¨ë¸ì„ ì‚¬ìš©í•´ ì‹¤ì œ ì¶”ì²œ ê²°ê³¼ë¥¼ ìƒì„±í•˜ëŠ” ì˜ˆì‹œë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.
"""
import os
import glob
import random
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim

from torch.utils.data import DataLoader
import logging
from src.logger_config import setup_logger

# --- Local Imports ---
# ë‹¤ë¥¸ íŒŒì¼ì— ì •ì˜ëœ í•¨ìˆ˜ë‚˜ ì„¤ì •ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
import src.settings as config  # í•™ìŠµì— í•„ìš”í•œ ì—¬ëŸ¬ ì„¤ì •ê°’(ì˜ˆ: íŒŒì¼ ê²½ë¡œ, ëª¨ë¸ íŒŒë¼ë¯¸í„°)ì„ ë‹´ê³  ìžˆëŠ” íŒŒì¼
from src.datasets.sequence_dataset import SequenceDataset  # ë°ì´í„°ë¥¼ ëª¨ë¸ì— ìž…ë ¥í•˜ê¸° ì¢‹ì€ í˜•íƒœë¡œ ë§Œë“¤ì–´ì£¼ëŠ” í´ëž˜ìŠ¤
from src.models.gru_model import GruModel  # ìš°ë¦¬ê°€ ì‚¬ìš©í•  ì¶”ì²œ ëª¨ë¸ì˜ êµ¬ì¡°ê°€ ì •ì˜ëœ í´ëž˜ìŠ¤
from src.data_processing import load_and_preprocess_data_with_split  # ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ê³  ëª¨ë¸ í•™ìŠµì— ë§žê²Œ ê°€ê³µí•˜ëŠ” í•¨ìˆ˜
from src.training_engine import train_model_with_validation, evaluate_model, generate_recommendations  # ëª¨ë¸ì„ í•™ìŠµ, í‰ê°€, ì¶”ì²œ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ë“¤
from src.utils import transfer_weights, collate_fn  # í•™ìŠµì— ë„ì›€ì´ ë˜ëŠ” ì¶”ê°€ í•¨ìˆ˜ë“¤

# GPU ë©”ëª¨ë¦¬ ë° ì—°ì‚° ìµœì í™” ì„¤ì •
# ì´ ì„¤ì •ë“¤ì€ GPUë¥¼ ì‚¬ìš©í•  ë•Œ ë” ë¹ ë¥¸ ê³„ì‚°ì„ ê°€ëŠ¥í•˜ê²Œ í•´ì¤ë‹ˆë‹¤.
torch.backends.cudnn.benchmark = True
torch.backends.cudnn.deterministic = False
torch.backends.cuda.matmul.allow_tf32 = True
torch.backends.cudnn.allow_tf32 = True


def main():
    """
    ë©”ì¸ í•¨ìˆ˜: ì „ì²´ í•™ìŠµ ê³¼ì •ì„ ìˆœì„œëŒ€ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.
    """
    # ë¡œê·¸ ì„¤ì •: í”„ë¡œê·¸ëž¨ ì‹¤í–‰ ì¤‘ ë°œìƒí•˜ëŠ” ìƒí™©ë“¤ì„ ê¸°ë¡í•˜ê¸° ìœ„í•œ ì„¤ì •
    setup_logger()
    logger = logging.getLogger(__name__)

    # í˜„ìž¬ ì‚¬ìš©í•˜ëŠ” ìž¥ì¹˜(CPU ë˜ëŠ” GPU) ì •ë³´ ì¶œë ¥
    logger.info(f"ì§€ê¸ˆ ì‚¬ìš©í•˜ëŠ” ìž¥ì¹˜ëŠ” '{config.DEVICE}' ìž…ë‹ˆë‹¤! (GPU ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ 'cuda'ë¡œ ë‚˜ì™€ìš”)")

    # --- 0. ë°ì´í„° ë¡œë“œ ---
    logger.info("Parquet íŒŒì¼ ë¡œë“œ ì¤‘...")
    # ì„¤ì • íŒŒì¼ì— ì§€ì •ëœ ê²½ë¡œì—ì„œ ë°ì´í„° íŒŒì¼ì„ ì°¾ìŠµë‹ˆë‹¤.
    parquet_files = glob.glob(config.DATA_PATH)
    if not parquet_files:
        # ë°ì´í„° íŒŒì¼ì´ ì—†ìœ¼ë©´ ê²½ê³  ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•˜ê³  í”„ë¡œê·¸ëž¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.
        logger.warning(f"ê²½ê³ : '{config.DATA_PATH}' ê²½ë¡œì—ì„œ Parquet íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    df_full = pd.concat(map(pd.read_parquet, parquet_files), ignore_index=True)
    logger.info(f"{len(df_full)}ê°œ í–‰ ë¡œë“œ ì™„ë£Œ.")


    # --- 1. ë°ì´í„° ì „ì²˜ë¦¬ ë° ë¶„í•  ---
    # ë¶ˆëŸ¬ì˜¨ ë°ì´í„°ë¥¼ ëª¨ë¸ í•™ìŠµì— ì‚¬ìš©í•  ìˆ˜ ìžˆë„ë¡ ê°€ê³µí•˜ê³ , í•™ìŠµ/ê²€ì¦/í…ŒìŠ¤íŠ¸ ìš©ìœ¼ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤.
    # ì´ ê³¼ì •ì—ì„œ ê° ì•„ì´í…œê³¼ ì´ë²¤íŠ¸ì— ê³ ìœ í•œ ë²ˆí˜¸ë¥¼ ë¶™ì—¬ì¤ë‹ˆë‹¤.
    (
        train_samples, valid_samples, test_samples,  # í•™ìŠµ, ê²€ì¦, í…ŒìŠ¤íŠ¸ìš© ë°ì´í„°
        item_id_to_idx, event_to_idx, idx_to_item_id,  # ì•„ì´í…œ/ì´ë²¤íŠ¸ì™€ ê³ ìœ  ë²ˆí˜¸ ì‚¬ì´ì˜ ë³€í™˜ ì •ë³´
        item_idx_to_embedded_name, df_item_info, class_weights  # ì•„ì´í…œ ì •ë³´ ë° í´ëž˜ìŠ¤ ê°€ì¤‘ì¹˜
    ) = load_and_preprocess_data_with_split(
        df_full,
        min_len_for_split=config.MIN_LEN_FOR_SEQ_SPLIT,  # ì‚¬ìš©ìžì˜ í–‰ë™ ì‹œí€€ìŠ¤ë¥¼ ë‚˜ëˆ„ê¸° ìœ„í•œ ìµœì†Œ ê¸¸ì´
    )

    # --- ë©”ëª¨ë¦¬ ê´€ë¦¬ ---
    # ìž„ë² ë”©(í…ìŠ¤íŠ¸ë¥¼ ìˆ«ìžë¡œ ë³€í™˜) ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìœ¼ë¯€ë¡œ, ë” ì´ìƒ í•„ìš” ì—†ëŠ” ëª¨ë¸ì„ ë©”ëª¨ë¦¬ì—ì„œ ì œê±°í•˜ì—¬ ìžì›ì„ í™•ë³´í•©ë‹ˆë‹¤.
    logger.info("ìž„ë² ë”© ìƒì„±ì´ ì™„ë£Œë˜ì–´ SentenceTransformer ëª¨ë¸ì„ ë©”ëª¨ë¦¬ì—ì„œ í•´ì œí•©ë‹ˆë‹¤.")

    # --- 2. ë°ì´í„° ë¡œë” ì¤€ë¹„ ---
    # ë°ì´í„°ë¥¼ ëª¨ë¸ì— íš¨ìœ¨ì ìœ¼ë¡œ ê³µê¸‰í•˜ê¸° ìœ„í•œ 'ë°ì´í„° ë¡œë”'ë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤.
    # SequenceDatasetì€ ë°ì´í„°ë¥¼ ëª¨ë¸ì— ë§žëŠ” í˜•íƒœë¡œ í•˜ë‚˜ì”© êº¼ë‚´ì£¼ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.
    train_dataset = SequenceDataset(train_samples, is_train=True)
    valid_dataset = SequenceDataset(valid_samples)
    test_dataset = SequenceDataset(test_samples)

    # í˜„ìž¬ ì»´í“¨í„°ì˜ CPU ì½”ì–´ ê°œìˆ˜ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.
    cpu_count = os.cpu_count() or 0
    logger.info(f"CPU ì½”ì–´ ê°œìˆ˜: {cpu_count}")

    # ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ë•Œ ì—¬ëŸ¬ CPU ì½”ì–´ë¥¼ ì‚¬ìš©í•˜ì—¬ ë” ë¹ ë¥´ê²Œ ì²˜ë¦¬í•˜ë„ë¡ ì„¤ì •í•©ë‹ˆë‹¤.
    # í•˜ì§€ë§Œ Windows í™˜ê²½ì—ì„œëŠ” ì´ ê¸°ëŠ¥ì´ ë¬¸ì œë¥¼ ì¼ìœ¼í‚¬ ìˆ˜ ìžˆì–´ 0ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.
    num_workers = 0
    logger.info(f"ë°ì´í„° ë¡œë” ì›Œì»¤ ê°œìˆ˜: {num_workers}")
    
    # pin_memoryì™€ persistent_workersëŠ” num_workersê°€ 0ë³´ë‹¤ í´ ë•Œ,
    # ë°ì´í„°ë¥¼ GPUë¡œ ë” ë¹¨ë¦¬ ì „ì†¡í•˜ê¸° ìœ„í•œ ì„¤ì •ìž…ë‹ˆë‹¤.
    pin_memory = True if num_workers > 0 else False
    persistent_workers = True if num_workers > 0 else False
    
    # prefetch_factorëŠ” ë¯¸ë¦¬ ë°ì´í„°ë¥¼ ì¤€ë¹„í•´ë‘ì–´ í•™ìŠµ ì†ë„ë¥¼ ë†’ì´ëŠ” ì„¤ì •ìž…ë‹ˆë‹¤.
    prefetch_factor = 2 if num_workers > 0 else None
    logger.info(f"í”„ë¦¬íŒ¨ì¹˜ íŒ©í„°: {prefetch_factor}")

    # DataLoaderëŠ” ë°ì´í„°ë¥¼ 'ë°°ì¹˜(batch)' ë‹¨ìœ„ë¡œ ë¬¶ì–´ ëª¨ë¸ì— ì „ë‹¬í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.
    # ì´ë¥¼ í†µí•´ í•™ìŠµì„ ë” ì•ˆì •ì ì´ê³  íš¨ìœ¨ì ìœ¼ë¡œ ë§Œë“­ë‹ˆë‹¤.
    train_loader = DataLoader(
        train_dataset, batch_size=config.BATCH_SIZE, shuffle=True,  # í•™ìŠµ ë°ì´í„°ëŠ” ìˆœì„œë¥¼ ì„žì–´ ì‚¬ìš©í•©ë‹ˆë‹¤.
        collate_fn=collate_fn, num_workers=num_workers,
        pin_memory=pin_memory, persistent_workers=persistent_workers,
        prefetch_factor=prefetch_factor,
    )
    valid_loader = DataLoader(
        valid_dataset, batch_size=config.BATCH_SIZE, shuffle=False,  # ê²€ì¦ ë°ì´í„°ëŠ” ìˆœì„œë¥¼ ì„žì§€ ì•ŠìŠµë‹ˆë‹¤.
        collate_fn=collate_fn, num_workers=num_workers,
        pin_memory=pin_memory, persistent_workers=persistent_workers,
        prefetch_factor=prefetch_factor,
    )
    test_loader = DataLoader(
        test_dataset, batch_size=config.BATCH_SIZE, shuffle=False,  # í…ŒìŠ¤íŠ¸ ë°ì´í„°ë„ ìˆœì„œë¥¼ ì„žì§€ ì•ŠìŠµë‹ˆë‹¤.
        collate_fn=collate_fn, num_workers=num_workers,
        pin_memory=pin_memory, persistent_workers=persistent_workers,
        prefetch_factor=prefetch_factor,
    )

    # --- 3. ëª¨ë¸ ì´ˆê¸°í™” ---
    # ì¶”ì²œ ëª¨ë¸(GruModel)ì„ ìƒì„±í•˜ê³  í•„ìš”í•œ ì„¤ì •ê°’ë“¤ì„ ì „ë‹¬í•©ë‹ˆë‹¤.
    model_args = {
        "device": config.DEVICE,  # ëª¨ë¸ì´ ê³„ì‚°ì„ ìˆ˜í–‰í•  ìž¥ì¹˜ (CPU ë˜ëŠ” GPU)
        "name_embedding_dim": config.NAME_EMBEDDING_DIM,  # ì•„ì´í…œ ì´ë¦„ ì •ë³´ë¥¼ ì–¼ë§ˆë‚˜ ìžì„¸í•˜ê²Œ í‘œí˜„í• ì§€ ê²°ì •
        "event_embedding_dim": config.EVENT_EMBEDDING_DIM,  # ì´ë²¤íŠ¸(ì˜ˆ: 'í´ë¦­', 'êµ¬ë§¤') ì •ë³´ë¥¼ ì–¼ë§ˆë‚˜ ìžì„¸í•˜ê²Œ í‘œí˜„í• ì§€ ê²°ì •
        "gru_hidden_dim": config.GRU_HIDDEN_DIM,  # ëª¨ë¸ì˜ ê¸°ì–µ ëŠ¥ë ¥(ë³µìž¡ì„±)ì„ ê²°ì •
        "dropout_rate": config.DROPOUT_RATE,  # ëª¨ë¸ì´ í•™ìŠµ ë°ì´í„°ì—ë§Œ ë„ˆë¬´ ì¹˜ìš°ì¹˜ì§€ ì•Šë„ë¡(ê³¼ì í•© ë°©ì§€) ì¼ë¶€ ì •ë³´ë¥¼ ë¬´ìž‘ìœ„ë¡œ ë¬´ì‹œí•˜ëŠ” ë¹„ìœ¨
        "gru_num_layers": config.GRU_NUM_LAYERS,  # ëª¨ë¸ì˜ ê¹Šì´ë¥¼ ê²°ì • (ì–¼ë§ˆë‚˜ ë§Žì€ ì¸µì„ ìŒ“ì„ì§€)
        "n_events": len(event_to_idx),  # ì „ì²´ ì´ë²¤íŠ¸ì˜ ì¢…ë¥˜ ìˆ˜
        "n_items": len(item_id_to_idx),  # ì „ì²´ ì•„ì´í…œì˜ ì¢…ë¥˜ ìˆ˜
    }
    model = GruModel(**model_args)

    # ë§Œì•½ ì´ì „ì— í•™ìŠµì‹œí‚¨ ëª¨ë¸ íŒŒì¼ì´ ìžˆë‹¤ë©´, ê·¸ ìƒíƒœë¥¼ ë¶ˆëŸ¬ì™€ì„œ ì´ì–´ì„œ í•™ìŠµí•©ë‹ˆë‹¤.
    if os.path.exists(config.MODEL_SAVE_PATH):
        logger.info("ì €ìž¥ëœ ëª¨ë¸ ê°€ì¤‘ì¹˜ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤... ðŸ’¾")
        old_state_dict = torch.load(config.MODEL_SAVE_PATH)  # ì €ìž¥ëœ ëª¨ë¸ ê°€ì¤‘ì¹˜(íŒŒë¼ë¯¸í„°)ë¥¼ ë¶ˆëŸ¬ì˜´
        new_model_state_dict = transfer_weights(old_state_dict, model)  # ì´ì „ ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ë¥¼ ìƒˆ ëª¨ë¸ êµ¬ì¡°ì— ë§žê²Œ ì¡°ì •
        model.load_state_dict(new_model_state_dict)  # ìƒˆ ëª¨ë¸ì— ê°€ì¤‘ì¹˜ë¥¼ ì ìš©
        logger.info("ê°€ì¤‘ì¹˜ ì´ì „ ì„±ê³µ! âœ…")

    # ëª¨ë¸ì„ ì§€ì •ëœ ìž¥ì¹˜(GPU ë˜ëŠ” CPU)ë¡œ ë³´ëƒ…ë‹ˆë‹¤.
    model.to(config.DEVICE)

    # ëª¨ë¸ì˜ ì´ íŒŒë¼ë¯¸í„° ìˆ˜ ë¡œê¹…
    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    logger.info(f"ëª¨ë¸ì˜ ì´ í•™ìŠµ ê°€ëŠ¥ íŒŒë¼ë¯¸í„° ìˆ˜: {total_params:,}ê°œ")
    
    # ì˜µí‹°ë§ˆì´ì €(Optimizer): ëª¨ë¸ì´ ì •ë‹µì„ ë” ìž˜ ë§žížˆë„ë¡ íŒŒë¼ë¯¸í„°ë¥¼ ìˆ˜ì •í•˜ëŠ” ë°©ë²•ì„ ê²°ì • (ì—¬ê¸°ì„œëŠ” AdamW ì‚¬ìš©)
    optimizer = optim.AdamW(model.parameters(), lr=config.LEARNING_RATE, weight_decay=config.WEIGHT_DECAY)
    
    # ìŠ¤ì¼€ì¤„ëŸ¬(Scheduler): í•™ìŠµì´ ì§„í–‰ë¨ì— ë”°ë¼ í•™ìŠµë¥ (learning rate)ì„ ì¡°ì ˆí•˜ì—¬ ë” ì •êµí•˜ê²Œ í•™ìŠµí•˜ë„ë¡ ë„ì™€ì¤Œ
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config.N_EPOCHS, eta_min=1e-6)
    
    # ì†ì‹¤ í•¨ìˆ˜(Loss Function): ëª¨ë¸ì˜ ì˜ˆì¸¡ì´ ì‹¤ì œ ì •ë‹µê³¼ ì–¼ë§ˆë‚˜ ë‹¤ë¥¸ì§€(ì˜¤ì°¨)ë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜
    # ê³„ì‚°ëœ í´ëž˜ìŠ¤ ê°€ì¤‘ì¹˜ë¥¼ GPUë¡œ ì´ë™í•˜ì—¬ ì†ì‹¤ í•¨ìˆ˜ì— ì ìš©í•©ë‹ˆë‹¤.
    class_weights_tensor = class_weights.to(config.DEVICE)
    criterion = nn.CrossEntropyLoss(weight=class_weights_tensor, ignore_index=0, label_smoothing=0.1)
    
    # --- 4. ëª¨ë¸ í•™ìŠµ ë° ê²€ì¦ ---
    logger.info("ëª¨ë¸ í•™ìŠµì„ ì‹œìž‘í•©ë‹ˆë‹¤... ðŸš€")
    # ì„¤ì •ëœ ê°’ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ëª¨ë¸ í•™ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤.
    trained_model = train_model_with_validation(
        model=model,  # ìš°ë¦¬ê°€ ë§Œë“  ëª¨ë¸
        train_loader=train_loader,  # í•™ìŠµìš© ë°ì´í„° ë¡œë”
        valid_loader=valid_loader,  # ê²€ì¦ìš© ë°ì´í„° ë¡œë”
        criterion=criterion,  # ì†ì‹¤ í•¨ìˆ˜
        optimizer=optimizer,  # ì˜µí‹°ë§ˆì´ì €
        scheduler=scheduler,  # ìŠ¤ì¼€ì¤„ëŸ¬
        n_epochs=config.N_EPOCHS,  # ì „ì²´ í•™ìŠµ ë°ì´í„°ë¥¼ ëª‡ ë²ˆ ë°˜ë³µí•´ì„œ ë³¼ì§€ ê²°ì •
        k_metrics=config.K_FOR_METRICS,  # ìƒìœ„ ëª‡ ê°œì˜ ì¶”ì²œ ì¤‘ ì •ë‹µì´ ìžˆëŠ”ì§€ í‰ê°€í• ì§€ ê²°ì •
        device=config.DEVICE,  # ê³„ì‚° ìž¥ì¹˜
        accumulation_steps=config.ACCUMULATION_STEPS,
    )
    logger.info("ëª¨ë¸ í•™ìŠµ ì™„ë£Œ! ðŸŽ‰")

    # --- 5. ìµœì¢… ëª¨ë¸ í‰ê°€ ---
    logger.info("ìµœì¢… ëª¨ë¸ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤... ðŸ“Š")
    # í•™ìŠµì´ ëë‚œ ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì´ìš©í•´ ìµœì¢… ì„±ëŠ¥ì„ í™•ì¸í•©ë‹ˆë‹¤.
    test_loss, test_recall, test_mrr, test_accuracy = evaluate_model(
        trained_model, test_loader, criterion, k=config.K_FOR_METRICS, device=config.DEVICE
    )
    logger.info(
        f"ìµœì¢… í…ŒìŠ¤íŠ¸ ê²°ê³¼: Loss: {test_loss:.4f} | "
        f"Recall@{config.K_FOR_METRICS}: {test_recall:.4f} | "  # ìƒìœ„ Kê°œ ì¶”ì²œ ì¤‘ ì‹¤ì œ ì •ë‹µì´ í¬í•¨ëœ ë¹„ìœ¨
        f"MRR@{config.K_FOR_METRICS}: {test_mrr:.4f} | "      # ì •ë‹µ ìˆœìœ„ì˜ ì—­ìˆ˜ í‰ê·  (ì •ë‹µì„ ì–¼ë§ˆë‚˜ ë¹¨ë¦¬ ë§žì¶”ëŠ”ì§€)
        f"Accuracy: {test_accuracy:.2f}"                     # ëª¨ë¸ì´ ì–¼ë§ˆë‚˜ ì •í™•í•˜ê²Œ ì˜ˆì¸¡í•˜ëŠ”ì§€
    )

    # --- 6. ëª¨ë¸ ì €ìž¥ ---
    logger.info(f"í•™ìŠµëœ ëª¨ë¸ì„ '{config.MODEL_SAVE_PATH}'ì— ì €ìž¥í•©ë‹ˆë‹¤... ðŸ’¾")
    # í•™ìŠµì´ ì™„ë£Œëœ ëª¨ë¸ì˜ íŒŒë¼ë¯¸í„°ë“¤ì„ íŒŒì¼ë¡œ ì €ìž¥í•˜ì—¬ ë‚˜ì¤‘ì— ë‹¤ì‹œ ì‚¬ìš©í•  ìˆ˜ ìžˆë„ë¡ í•©ë‹ˆë‹¤.
    torch.save(trained_model.state_dict(), config.MODEL_SAVE_PATH)
    logger.info("ëª¨ë¸ ì €ìž¥ ì™„ë£Œ! âœ…")

    # --- 7. ì¶”ì²œ ìƒì„± ë° ê²°ê³¼ í™•ì¸ (ì˜ˆì‹œ) ---
    # í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ìžˆì„ ê²½ìš°, ì´ë¥¼ ì´ìš©í•´ ì‹¤ì œ ì¶”ì²œ ê²°ê³¼ë¥¼ ë§Œë“¤ì–´ë³´ëŠ” ì˜ˆì‹œìž…ë‹ˆë‹¤.
    if test_samples:
        logger.info("ì¶”ì²œ ê²°ê³¼ ìƒì„± ì˜ˆì‹œ... ðŸ›ï¸")
        
        # ì•„ì´í…œ ì •ë³´ì—ì„œ ë¬´ìž‘ìœ„ë¡œ 1~10ê°œì˜ ì•„ì´í…œ-ì´ë²¤íŠ¸ ì‹œí€€ìŠ¤ë¥¼ ìƒ˜í”Œë§í•©ë‹ˆë‹¤.
        item_event_sequences = df_item_info.sample(n=random.randint(1, 10))
        # ìƒ˜í”Œë§ëœ ë°ì´í„°ë¥¼ ëª¨ë¸ ìž…ë ¥ í˜•ì‹ì— ë§žê²Œ ë³€í™˜í•©ë‹ˆë‹¤.
        item_event_sequences = item_event_sequences.apply(
            lambda x: (
                x["name"],  # ìƒí’ˆëª…
                random.choice(list(event_to_idx.keys())[1:]),  # ëžœë¤ í–‰ë™ ('í´ë¦­', 'êµ¬ë§¤' ë“±)
                x["c0_name"],  # ëŒ€ë¶„ë¥˜ ì¹´í…Œê³ ë¦¬
                x["c1_name"],  # ì¤‘ë¶„ë¥˜ ì¹´í…Œê³ ë¦¬
                x["c2_name"],  # ì†Œë¶„ë¥˜ ì¹´í…Œê³ ë¦¬
            ),
            axis=1,
        ).tolist()
        
        # ëª¨ë¸ì— ìž…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•  ì‹œí€€ìŠ¤ ì •ë³´ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
        logger.info(f"ì¶”ì²œ ìƒì„±ì„ ìœ„í•œ ìž…ë ¥ ì‹œí€€ìŠ¤:")
        for item_event_sequence in item_event_sequences:
            logger.info(
                f"  - ìƒí’ˆëª…: {item_event_sequence[0]:>80}, í–‰ë™: {item_event_sequence[1]:>20}"
                f"  - ì¹´í…Œê³ ë¦¬: {(item_event_sequence[2] if item_event_sequence[2] else ' '):<20}, "
                f"{(item_event_sequence[3] if item_event_sequence[3] else ' '):<20}, " 
                f"{(item_event_sequence[4] if item_event_sequence[4] else ' '):<20}"
            )

        # í•™ìŠµëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì¶”ì²œ ìƒí’ˆ ëª©ë¡ì„ ìƒì„±í•©ë‹ˆë‹¤.
        recommendations = generate_recommendations(
            model=trained_model,
            item_event_sequences=item_event_sequences,  # ìž…ë ¥ ì‹œí€€ìŠ¤
            top_n=config.TOP_N,  # ìƒìœ„ ëª‡ ê°œë¥¼ ì¶”ì²œí• ì§€ ê²°ì •
            device=config.DEVICE,
            idx_to_item_id=idx_to_item_id,
            event_to_idx=event_to_idx,
            df_item_info=df_item_info,
        )

        # ìƒì„±ëœ ì¶”ì²œ ê²°ê³¼ë¥¼ í‘œ í˜•íƒœë¡œ ì¶œë ¥í•©ë‹ˆë‹¤.
        logger.info(f"\n--- ìƒìœ„ {config.TOP_N}ê°œ ì¶”ì²œ ìƒí’ˆ ---")
        if isinstance(recommendations, pd.DataFrame) and not recommendations.empty:
            logger.info(f"\n{recommendations.to_string()}")
        else:
            logger.warning("ì¶”ì²œ ìƒí’ˆ ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # GPU ë©”ëª¨ë¦¬ë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤.
    torch.cuda.empty_cache()
    torch.cuda.reset_peak_memory_stats()

    logger.info("\n--- ëª¨ë“  ìž‘ì—… ì™„ë£Œ ---")


if __name__ == "__main__":
    # ì´ ìŠ¤í¬ë¦½íŠ¸ê°€ ì§ì ‘ ì‹¤í–‰ë  ë•Œ main() í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.
    main()
