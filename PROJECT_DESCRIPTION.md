# 프로젝트 단계별 설명

이 문서는 추천 시스템 프로젝트의 전체 과정을 단계별로 나누어 설명합니다. 각 단계는 데이터 준비부터 모델 학습, 그리고 실제 추천 생성에 이르기까지의 과정을 상세히 다룹니다.

## 1. 데이터 불러오기

추천 모델을 학습시키기 위한 첫 단계는 데이터를 불러오는 것입니다.

- **데이터 소스**: 데이터는 Parquet 형식의 파일에 저장되어 있습니다. Parquet은 대용량 데이터를 효율적으로 저장하고 처리하기 좋은 컬럼 기반 파일 형식입니다.
- **로딩 과정**: `train.py` 스크립트는 `config.DATA_PATH`에 지정된 경로의 모든 Parquet 파일을 찾아 `pandas` 데이터프레임으로 불러옵니다. 여러 파일이 있는 경우, 모든 데이터를 하나로 합쳐 전체 데이터셋을 구성합니다.

## 2. 데이터 전처리

원본 데이터를 모델이 학습할 수 있는 형태로 가공하는 과정입니다. 이 단계는 `src/data_processing.py`의 `load_and_preprocess_data_with_split` 함수를 통해 주로 이루어집니다.

- **사용자 행동 시퀀스 생성**: 사용자의 행동 로그를 시간 순서대로 정렬하여, 각 사용자별로 아이템 및 이벤트(조회, 구매 등) 시퀀스를 생성합니다.
- **데이터 분할**: 생성된 시퀀스 데이터를 **학습(Training) / 검증(Validation) / 테스트(Test)** 용도로 분할합니다. 이는 모델의 성능을 객관적으로 평가하기 위한 필수 과정입니다.
    - **학습 데이터**: 모델을 학습시키는 데 사용됩니다.
    - **검증 데이터**: 학습 과정에서 모델의 성능을 중간 점검하고, 최적의 파라미터를 찾는 데 사용됩니다.
    - **테스트 데이터**: 학습이 완료된 모델의 최종 성능을 평가하는 데 사용됩니다.
- **인덱싱(Indexing)**: 모델은 텍스트 형태의 아이템 ID나 이벤트 이름을 직접 이해할 수 없습니다. 따라서 각 아이템과 이벤트에 고유한 숫자 인덱스를 부여합니다.
    - `item_id_to_idx`: 아이템 ID를 고유 번호로 변환합니다.
    - `event_to_idx`: '조회', '구매' 등의 이벤트를 고유 번호로 변환합니다.
- **이름 임베딩**: 상품의 이름(텍스트)을 `SentenceTransformer` 모델을 사용하여 의미를 담은 숫자 벡터(임베딩)로 변환합니다. 이를 통해 모델은 상품 이름의 의미적 유사성을 파악할 수 있게 됩니다.

## 3. 모델 준비

학습을 진행할 추천 모델을 준비하고, 학습에 필요한 환경을 설정합니다.

- **모델 아키텍처**: **GRU(Gated Recurrent Unit)** 기반의 모델(`src/models/gru_model.py`)을 사용합니다. GRU는 RNN의 일종으로, 사용자의 행동 시퀀스 데이터에서 시간적 순서와 패턴을 학습하는 데 효과적입니다.
    - **입력**: 사용자의 (아이템, 이벤트) 시퀀스
    - **출력**: 다음에 올 확률이 가장 높은 아이템 예측
- **데이터 로더(Data Loader)**: 전처리된 데이터를 모델에 효율적으로 공급하기 위해 `torch.utils.data.DataLoader`를 사용합니다. 데이터를 배치(batch) 단위로 묶어 처리함으로써 학습을 안정화하고 속도를 높입니다.
- **학습 환경 설정**:
    - **손실 함수 (Loss Function)**: `CrossEntropyLoss`를 사용하여 모델의 예측이 실제 정답과 얼마나 다른지(오차)를 계산합니다.
    - **옵티마이저 (Optimizer)**: `Adam` 옵티마이저를 사용하여 계산된 손실을 바탕으로 모델의 파라미터를 업데이트하며 학습을 진행합니다.
    - **스케줄러 (Scheduler)**: `ReduceLROnPlateau`를 사용하여 검증 데이터의 손실이 개선되지 않을 때 학습률(learning rate)을 동적으로 조절하여, 모델이 최적점에 더 잘 수렴하도록 돕습니다.

## 4. 학습

준비된 데이터와 모델을 바탕으로 실제 학습을 진행합니다. 이 과정은 `train.py`가 메인 스크립트 역할을 하며, 핵심 로직은 `src/training_engine.py`의 `train_model_with_validation` 함수에 구현되어 있습니다.

- **학습 루프 (Training Loop)**:
    1.  데이터 로더로부터 학습 데이터를 배치 단위로 가져옵니다.
    2.  가져온 데이터를 모델에 입력하여 예측 결과를 얻습니다.
    3.  손실 함수를 이용해 예측 결과와 실제 정답 간의 오차를 계산합니다.
    4.  계산된 오차를 바탕으로 옵티마이저가 모델의 가중치를 업데이트합니다. (역전파)
    5.  설정된 epoch(전체 데이터 반복 횟수)만큼 위 과정을 반복합니다.
- **검증 (Validation)**: 하나의 epoch 학습이 끝날 때마다, 검증 데이터를 사용하여 모델의 성능(`Recall@K`, `MRR@K` 등)을 평가합니다. 이를 통해 모델이 과적합(overfitting)되지 않고 일반화 성능을 유지하는지 모니터링합니다.
- **모델 저장**: 검증 성능이 가장 좋았던 시점의 모델 가중치를 `model_artifacts/` 폴더에 저장하여, 나중에 예측 서비스에 사용할 수 있도록 합니다.

## 5. 예측 또는 추론

학습된 모델을 사용하여 새로운 추천 결과를 생성하는 과정입니다. `predict.py` 스크립트에서 이 과정을 확인할 수 있습니다.

- **추론 과정**:
    1.  `model_artifacts/`에 저장된 학습 완료 모델과 관련 데이터(아이템-인덱스 맵핑 등)를 불러옵니다.
    2.  모델을 **추론 모드 (`.eval()`)**로 전환합니다. (학습 시에만 사용하는 드롭아웃 등의 기능을 비활성화)
    3.  추천을 받고자 하는 사용자의 행동 시퀀스(예: 최근에 본 상품, 장바구니에 담은 상품 목록)를 입력으로 준비합니다.
    4.  준비된 시퀀스를 모델에 입력하여, 다음에 올 확률이 높은 아이템들의 순위를 예측합니다.
    5.  예측된 아이템 순위에서 상위 N개를 선택하여 최종 추천 목록으로 사용자에게 제공합니다.

## 6. 개선 방안

현재 프로젝트를 더욱 발전시키기 위한 몇 가지 아이디어입니다.

- **추론 속도 개선 (Faster Inference)**:
    - 현재는 모든 아이템에 대해 예측 확률을 계산하므로 아이템 수가 많아지면 속도가 느려질 수 있습니다.
    - **Faiss**와 같은 라이브러리를 활용하여 **ANN(Approximate Nearest Neighbor)** 검색을 도입하면, 전체 아이템이 아닌 예측과 유사한 일부 아이템 후보군 내에서만 순위를 계산하여 추론 속도를 획기적으로 개선할 수 있습니다.
- **모델 아키텍처 변경**:
    - GRU 외에 **Transformer** 기반의 모델(예: SASRec, BERT4Rec)을 시도해볼 수 있습니다. Transformer는 더 긴 시퀀스에서도 중요한 패턴을 효과적으로 잡아내는 능력(Attention Mechanism)이 뛰어나 성능 향상을 기대할 수 있습니다.
- **하이퍼파라미터 최적화 (Hyperparameter Tuning)**:
    - 학습률, 배치 사이즈, GRU의 은닉층 크기 및 레이어 수 등 주요 하이퍼파라미터를 체계적으로 탐색(예: Grid Search, Bayesian Optimization)하여 최적의 조합을 찾으면 모델 성능을 극대화할 수 있습니다.
- **피처 엔지니어링 (Feature Engineering)**:
    - 현재는 상품명과 이벤트 유형을 주요 특징으로 사용하고 있습니다.
    - 상품의 **카테고리 정보, 가격, 브랜드명, 상품 상태, 크기**와 같은 추가적인 피처를 모델에 통합하면, 더욱 개인화되고 정교한 추천이 가능해집니다. 